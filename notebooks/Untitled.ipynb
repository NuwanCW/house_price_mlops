{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b69d115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.impute  import SimpleImputer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Dict, List, Tuple\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import json\n",
    "from argparse import Namespace\n",
    "from typing import Dict\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import json\n",
    "from argparse import Namespace\n",
    "from typing import Dict\n",
    "# import matplotlib.pyplot as plt\n",
    "# mlflow.set_tracking_uri(\"file:///tmp/my_tracking\")\n",
    "mlflow.set_tracking_uri(\"http://localhost:8003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec21e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elapsed_years(df, var):\n",
    "    # capture difference between year variable and year the house was sold\n",
    "    df[var] = df['YrSold'] - df[var]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_data_splits(X: pd.Series, y: np.ndarray, train_size: float = 0.7) -> Tuple:\n",
    "    \"\"\"Generate balanced data splits.\n",
    "    Args:\n",
    "        X (pd.Series): input features.\n",
    "        y (np.ndarray): encoded labels.\n",
    "        train_size (float, optional): proportion of data to use for training. Defaults to 0.7.\n",
    "    Returns:\n",
    "        Tuple: data splits as Numpy arrays.\n",
    "    \"\"\"\n",
    "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=train_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6d8280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_columns = [\n",
    "            \"LotArea\",\n",
    "            \"OverallQual\",\n",
    "            \"YearRemodAdd\",\n",
    "            \"BsmtQual\",\n",
    "            \"BsmtFinSF1\",\n",
    "            \"TotalBsmtSF\",\n",
    "            \"1stFlrSF\",\n",
    "            \"2ndFlrSF\",\n",
    "            \"GrLivArea\",\n",
    "            \"GarageCars\",\n",
    "            \"SalePrice\",\n",
    "            \"YrSold\"\n",
    "        ]\n",
    "def get_data():\n",
    "    df = pd.read_csv('../data/train.csv')\n",
    "    df =df[valid_columns]\n",
    "    df = df[df.SalePrice.notnull()]  # drop rows w/ no tag\n",
    "\n",
    "    # get columns as date, categorical and numerical types\n",
    "    vars_dates = ['YearRemodAdd']\n",
    "    vars_cat = [var for var in df.columns if df[var].dtypes == \"O\"]\n",
    "    vars_num = [var for var in df.columns if df[var].dtypes != \"O\" and var not in [\"Id\"]]\n",
    "\n",
    "\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df[vars_num] = imputer.fit_transform(df[vars_num])\n",
    "\n",
    "    imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "    df[vars_cat] = imputer.fit_transform(df[vars_cat])\n",
    "\n",
    "    for var in ['YearRemodAdd']:\n",
    "        df = elapsed_years(df, var)\n",
    "\n",
    "    ordinal_enc = OrdinalEncoder()\n",
    "    df[vars_cat] = ordinal_enc.fit_transform(df[vars_cat])\n",
    "    df.drop(columns=[\"YrSold\"],inplace=True)\n",
    "\n",
    "\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = get_data_splits(\n",
    "            X=df[df.columns[~df.columns.isin([\"SalePrice\"])]].to_numpy(),\n",
    "            y=df.SalePrice.to_numpy() / 1,\n",
    "        )\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test,ordinal_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15a37295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(filepath: str) -> Dict:\n",
    "    \"\"\"Load a dictionary from a JSON's filepath.\n",
    "    Args:\n",
    "        filepath (str): location of file.\n",
    "    Returns:\n",
    "        Dict: loaded JSON data.\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\") as fp:\n",
    "        d = json.load(fp)\n",
    "    return d\n",
    "args = Namespace(**load_dict(filepath='args_par.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "233c8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "def namespace_to_dict(namespace):\n",
    "    return {\n",
    "        k: namespace_to_dict(v) if isinstance(v, argparse.Namespace) else v\n",
    "        for k, v in vars(namespace).items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c671d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gbm = lgb.train(namespace_to_dict(args),\n",
    "#                 lgb_train,\n",
    "#                 num_boost_round=200,\n",
    "#                 valid_sets=lgb_eval,\n",
    "#                 callbacks=[lgb.early_stopping(stopping_rounds=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c86e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbm.predict(X_test, num_iteration=gbm.best_iteration)*100000\n",
    "\n",
    "# x_ax = range(len(y_test))\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(x_ax, y_test*1, label=\"original\")\n",
    "# plt.plot(x_ax, gbm.predict(X_test, num_iteration=gbm.best_iteration)*1, label=\"predicted\")\n",
    "# plt.title(\"Boston dataset test and predicted data\")\n",
    "# plt.xlabel('X')\n",
    "# plt.ylabel('Price')\n",
    "# plt.legend(loc='best',fancybox=True, shadow=True)\n",
    "# plt.grid(True)\n",
    "# plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a4bf007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error,mean_absolute_percentage_error,median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38a74075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "\n",
    "def get_metrics(y_true,y_pred):\n",
    "#     median_absolute_error=median_absolute_error(y_test, y_pred)\n",
    "#     mean_absolute_percentage_error=mean_absolute_percentage_error(y_test, y_pred)\n",
    "    mean_squared_error_=mean_squared_error(y_true, y_pred)\n",
    "#     mean_absolute_error=mean_absolute_error(y_test, y_pred)\n",
    "    r2_score_=r2_score(y_true, y_pred, multioutput='variance_weighted')\n",
    "    return (mean_squared_error_,r2_score_)\n",
    "\n",
    "def get_eval_metric(y_true,y_pred):\n",
    "    metrics = {\"overall\": {}}\n",
    "\n",
    "    # Overall metrics\n",
    "    mse,r2 = get_metrics(y_true, y_pred)\n",
    "\n",
    "    metrics[\"overall\"][\"MSE\"] = mse\n",
    "    metrics[\"overall\"][\"R2\"] = r2\n",
    "    metrics[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f34574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(args: Namespace, trial: optuna.trial._trial.Trial = None) -> Dict:\n",
    "    \"\"\"Train model on data.\n",
    "    Args:\n",
    "        args (Namespace): arguments to use for training.\n",
    "        df (pd.DataFrame): data for training.\n",
    "        trial (optuna.trial._trial.Trial, optional): optimization trial. Defaults to None.\n",
    "    Raises:\n",
    "        optuna.TrialPruned: early stopping of trial if it's performing poorly.\n",
    "    Returns:\n",
    "        Dict: artifacts from the run.\n",
    "    \"\"\"\n",
    "\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test,ordinal_enc = get_data()\n",
    "        \n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "\n",
    "    # Training\n",
    "    model = lgb.train(namespace_to_dict(args),\n",
    "                lgb_train,\n",
    "                num_boost_round=200,\n",
    "                valid_sets=lgb_eval,\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=5)])\n",
    "    \n",
    "  \n",
    "    train_mse,train_r2=get_metrics(y_train,model.predict(X_train, num_iteration=model.best_iteration))\n",
    "    val_mse,val_r2=get_metrics(y_val,model.predict(X_val, num_iteration=model.best_iteration))\n",
    "    \n",
    "   \n",
    "    print(f\"train_mse: {train_mse:.5f}, \" f\"train_r2: {train_r2:.5f},\" f\"val_mse: {val_mse:.5f}, \" f\"val_r2: {val_r2:.5f}\")\n",
    "\n",
    "    # Log\n",
    "    if not trial:\n",
    "        mlflow.log_metrics({\"train_mse\": train_mse, \"val_mse\": val_mse,\"train_r2\": train_r2, \"val_r2\":val_r2})\n",
    "\n",
    "    # Pruning (for optimization in next section)\n",
    "    if trial:  # pragma: no cover, optuna pruning\n",
    "        trial.report(val_mse, val_r2)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    # Threshold\n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "    performance = get_eval_metric(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "    return {\n",
    "        \"args\": args,\n",
    "        \"model\": model,\n",
    "        \"performance\": performance,\n",
    "        \"ordinal_enc\": ordinal_enc,\n",
    "    }\n",
    "\n",
    "\n",
    "def objective(args: Namespace, trial: optuna.trial._trial.Trial) -> float:\n",
    "    \"\"\"Objective function for optimization trials.\n",
    "    Args:\n",
    "        args (Namespace): arguments to use for training.\n",
    "        df (pd.DataFrame): data for training.\n",
    "        trial (optuna.trial._trial.Trial, optional): optimization trial.\n",
    "    Returns:\n",
    "        float: metric value to be used for optimization.\n",
    "    \"\"\"\n",
    "    # Parameters to tune\n",
    "    args.learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-2, 1e0)\n",
    "    args.power_t = trial.suggest_uniform(\"power_t\", 0.1, 0.5)\n",
    "\n",
    "    # Train & evaluate\n",
    "    artifacts = train(args=args, trial=trial)\n",
    "\n",
    "    # Set additional attributes\n",
    "    overall_performance = artifacts[\"performance\"][\"overall\"]\n",
    "#     logger.info(json.dumps(overall_performance, indent=2))\n",
    "    trial.set_user_attr(\"R2\", overall_performance[\"R2\"])\n",
    "\n",
    "    return overall_performance[\"R2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e8b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   \"boosting_type\": \"gbdt\",\n",
    "#     \"objective\": \"regression\",\n",
    "#     \"metric\": [\n",
    "#         \"l2\",\n",
    "#         \"l1\"\n",
    "#     ],\n",
    "#     \"num_leaves\": 50,\n",
    "#     \"learning_rate\": 0.05,\n",
    "#     \"feature_fraction\": 0.9,\n",
    "#     \"bagging_fraction\": 0.8,\n",
    "#     \"bagging_freq\": 10,\n",
    "#     \"verbose\": -1\n",
    "def save_dict(d: Dict, filepath: str, cls=None, sortkeys: bool = False) -> None:\n",
    "    \"\"\"Save a dictionary to a specific location.\n",
    "    Args:\n",
    "        d (Dict): data to save.\n",
    "        filepath (str): location of where to save the data.\n",
    "        cls (optional): encoder to use on dict data. Defaults to None.\n",
    "        sortkeys (bool, optional): whether to sort keys alphabetically. Defaults to False.\n",
    "    \"\"\"\n",
    "    with open(filepath, \"w\") as fp:\n",
    "        json.dump(d, indent=2, fp=fp, cls=cls, sort_keys=sortkeys)\n",
    "        fp.write(\"\\n\")       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8306b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(Namespace(**load_dict(filepath='args_par.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8bc2e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1710b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger\n",
    "import logging,sys\n",
    "from pathlib import Path\n",
    "from rich.logging import RichHandler\n",
    "LOGS_DIR = Path(\"./\", \"logs\")\n",
    "LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logging_config = {\n",
    "    \"version\": 1,\n",
    "    \"disabel_existing_loggers\": False,\n",
    "    \"formatters\": {\n",
    "        \"minimal\": {\"format\": \"%(message)s\"},\n",
    "        \"detailed\": {\n",
    "            \"format\": \"%(levelname)s %(asctime)s [%(name)s:%(filename)s:%(funcName)s:%(lineno)d]\\n%(message)s\\n\"\n",
    "        },\n",
    "    },\n",
    "    \"handlers\": {\n",
    "        \"console\": {\n",
    "            \"class\": \"logging.StreamHandler\",\n",
    "            \"stream\": sys.stdout,\n",
    "            \"formatter\": \"minimal\",\n",
    "            \"level\": logging.DEBUG,\n",
    "        },\n",
    "        \"info\": {\n",
    "            \"class\": \"logging.handlers.RotatingFileHandler\",\n",
    "            \"filename\": Path(LOGS_DIR, \"info.log\"),\n",
    "            \"maxBytes\": 10485760,  # 1 MB\n",
    "            \"backupCount\": 10,\n",
    "            \"formatter\": \"detailed\",\n",
    "            \"level\": logging.INFO,\n",
    "        },\n",
    "        \"error\": {\n",
    "            \"class\": \"logging.handlers.RotatingFileHandler\",\n",
    "            \"filename\": Path(LOGS_DIR, \"error.log\"),\n",
    "            \"maxBytes\": 10485760,  # 1 MB\n",
    "            \"backupCount\": 10,\n",
    "            \"formatter\": \"detailed\",\n",
    "            \"level\": logging.ERROR,\n",
    "        },\n",
    "    },\n",
    "    \"root\": {\n",
    "        \"handlers\": [\"console\", \"info\", \"error\"],\n",
    "        \"level\": logging.INFO,\n",
    "        \"propagate\": True,\n",
    "    },\n",
    "}\n",
    "\n",
    "logging.config.dictConfig(logging_config)\n",
    "logger = logging.getLogger()\n",
    "logger.handlers[0] = RichHandler(markup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e371491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tempfile\n",
    "from numpyencoder import NumpyEncoder\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "import joblib\n",
    "def train_model(\n",
    "    args_fp: str = \"./args_par.json\",\n",
    "    experiment_name: str = \"baselines_1\",\n",
    "    run_name: str = \"gbr\",\n",
    "    test_run: bool = False,\n",
    ") -> None:\n",
    "    \"\"\"Train a model given arguments.\n",
    "    Args:\n",
    "        args_fp (str): location of args.\n",
    "        experiment_name (str): name of experiment.\n",
    "        run_name (str): name of specific run in experiment.\n",
    "        test_run (bool, optional): If True, artifacts will not be saved. Defaults to False.\n",
    "    \"\"\"\n",
    "    # Load labeled data\n",
    "#     projects_fp = Path(config.DATA_DIR, \"train_cleaned.json\")\n",
    "#     projects = util.load_dict(filepath=projects_fp)\n",
    "#     df = pd.DataFrame(projects)\n",
    "\n",
    "    # Train\n",
    "    args = Namespace(**load_dict(filepath='args_par.json'))\n",
    "#     namespace_to_dict(args)\n",
    "    mlflow.set_experiment(experiment_name=experiment_name)\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "        logger.info(f\"Run ID: {run_id}\")\n",
    "        artifacts = train(args=args)\n",
    "        performance = artifacts[\"performance\"]\n",
    "        logger.info(json.dumps(performance, indent=2))\n",
    "\n",
    "        # Log metrics and parameters\n",
    "        performance = artifacts[\"performance\"]\n",
    "#         print(performance)\n",
    "        mlflow.log_metrics({\"MSE\": performance[\"overall\"][\"MSE\"]})\n",
    "        mlflow.log_metrics({\"R2\": performance[\"overall\"][\"R2\"]})\n",
    "        mlflow.log_params(vars(artifacts[\"args\"]))\n",
    "\n",
    "        # Log artifacts\n",
    "        with tempfile.TemporaryDirectory() as dp:\n",
    "            save_dict(vars(artifacts[\"args\"]), Path(dp, \"args_par.json\"), cls=NumpyEncoder)\n",
    "            joblib.dump(artifacts[\"model\"], Path(dp, \"model.pkl\"))\n",
    "            save_dict(performance, Path(dp, \"performance.json\"))\n",
    "            joblib.dump(artifacts[\"ordinal_enc\"], Path(dp, \"ordinal_enc.pkl\"))\n",
    "            mlflow.log_artifacts(dp)\n",
    "\n",
    "    # Save to config\n",
    "    if not test_run:  # pragma: no cover, actual run\n",
    "        open(Path(\"./\", \"run_id.txt\"), \"w\").write(run_id)\n",
    "        save_dict(performance, Path(\"./\", \"performance.json\"))\n",
    "\n",
    "\n",
    "def optimize(\n",
    "    args_fp: str = \"./args_par.json\",\n",
    "    study_name: str = \"optimization\",\n",
    "    num_trials: int = 20,\n",
    ") -> None:\n",
    "    \"\"\"Optimize hyperparameters.\n",
    "    Args:\n",
    "        args_fp (str): location of args.\n",
    "        study_name (str): name of optimization study.\n",
    "        num_trials (int): number of trials to run in study.\n",
    "    \"\"\"\n",
    "    # Load labeled data\n",
    "#     projects_fp = Path(config.DATA_DIR, \"train_cleaned.json\")\n",
    "#     projects = util.load_dict(filepath=projects_fp)\n",
    "#     df = pd.DataFrame(projects)\n",
    "\n",
    "    # Optimize\n",
    "    args = Namespace(**load_dict(filepath=args_fp))\n",
    "    pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
    "    study = optuna.create_study(study_name=study_name, direction=\"maximize\", pruner=pruner)\n",
    "    mlflow_callback = MLflowCallback(tracking_uri=mlflow.get_tracking_uri(), metric_name=\"R2\")\n",
    "    study.optimize(\n",
    "        lambda trial: objective(args, trial),\n",
    "        n_trials=num_trials,\n",
    "        callbacks=[mlflow_callback],\n",
    "    )\n",
    "\n",
    "    # Best trial\n",
    "    trials_df = study.trials_dataframe()\n",
    "    # print(trials_df.head())\n",
    "    trials_df = trials_df.sort_values([\"user_attrs_R2\"], ascending=False)\n",
    "    args = {**args.__dict__, **study.best_trial.params}\n",
    "    save_dict(d=args, filepath=args_fp, cls=NumpyEncoder)\n",
    "    logger.info(f\"\\nBest value (R2): {study.best_trial.value}\")\n",
    "    logger.info(f\"Best hyperparameters: {json.dumps(study.best_trial.params, indent=2)}\")\n",
    "\n",
    "\n",
    "def load_artifacts(run_id: str = None) -> Dict:\n",
    "    \"\"\"Load artifacts for a given run_id.\n",
    "    Args:\n",
    "        run_id (str): id of run to load artifacts from.\n",
    "    Returns:\n",
    "        Dict: run's artifacts.\n",
    "    \"\"\"\n",
    "    if not run_id:\n",
    "        run_id = open(Path(\"./\", \"run_id.txt\")).read()\n",
    "\n",
    "    # Locate specifics artifacts directory\n",
    "    experiment_id = mlflow.get_run(run_id=run_id).info.experiment_id\n",
    "    artifacts_dir = Path(\"./\", experiment_id, run_id, \"artifacts\")\n",
    "\n",
    "    # Load objects from run\n",
    "    args = Namespace(**load_dict(filepath=Path(artifacts_dir, \"args.json\")))\n",
    "    model = joblib.load(Path(artifacts_dir, \"model.pkl\"))\n",
    "    ordinal_enc = joblib.load(Path(artifacts_dir, \"ordinal_enc.pkl\"))\n",
    "    performance = load_dict(filepath=Path(artifacts_dir, \"performance.json\"))\n",
    "\n",
    "    return {\n",
    "        \"args\": args,\n",
    "        \"model\": model,\n",
    "        \"performance\": performance,\n",
    "        \"ordinal_enc\": ordinal_enc,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cbb78189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/3gwk63ms75j1d59250qhzlb40000gn/T/ipykernel_66368/437249340.py:76: ExperimentalWarning: MLflowCallback is experimental (supported from v1.4.0). The interface can change in the future.\n",
      "  mlflow_callback = MLflowCallback(tracking_uri=mlflow.get_tracking_uri(), metric_name=\"R2\")\n",
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l2: 6.08336e+08\tvalid_0's l1: 17750.1\n",
      "train_mse: 678835539.86193, train_r2: 0.89874,val_mse: 608336157.41514, val_r2: 0.89266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l2: 1.30938e+09\tvalid_0's l1: 21316.4\n",
      "train_mse: 670296052.33126, train_r2: 0.89591,val_mse: 1309380474.42838, val_r2: 0.78946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's l2: 1.03335e+09\tvalid_0's l1: 19692.5\n",
      "train_mse: 870320833.33549, train_r2: 0.85998,val_mse: 1033348640.74970, val_r2: 0.87414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's l2: 1.02837e+09\tvalid_0's l1: 18989.3\n",
      "train_mse: 612708835.95189, train_r2: 0.90419,val_mse: 1028372980.91414, val_r2: 0.83631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's l2: 8.82562e+08\tvalid_0's l1: 18874.4\n",
      "train_mse: 624644980.46993, train_r2: 0.90317,val_mse: 882562431.68685, val_r2: 0.86728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's l2: 4.92324e+08\tvalid_0's l1: 16132.6\n",
      "train_mse: 654839294.91838, train_r2: 0.89865,val_mse: 492324269.68615, val_r2: 0.90394\n",
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's l2: 1.08312e+09\tvalid_0's l1: 17376.2\n",
      "train_mse: 568014459.03928, train_r2: 0.90572,val_mse: 1083115974.97625, val_r2: 0.86750\n",
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's l2: 1.42837e+09\tvalid_0's l1: 21943.9\n",
      "train_mse: 573630599.05524, train_r2: 0.89927,val_mse: 1428371758.63743, val_r2: 0.79082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's l2: 9.4875e+08\tvalid_0's l1: 20879.7\n",
      "train_mse: 697411224.11578, train_r2: 0.88298,val_mse: 948749670.53462, val_r2: 0.81703\n",
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l2: 1.44426e+09\tvalid_0's l1: 22707.4\n",
      "train_mse: 435924797.38536, train_r2: 0.92676,val_mse: 1444261069.90996, val_r2: 0.80741\n",
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's l2: 7.38553e+08\tvalid_0's l1: 17758.1\n",
      "train_mse: 711354862.80805, train_r2: 0.88973,val_mse: 738553165.06609, val_r2: 0.89525\n",
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's l2: 6.85033e+08\tvalid_0's l1: 18158.8\n",
      "train_mse: 722557472.73892, train_r2: 0.89079,val_mse: 685033016.75769, val_r2: 0.87753\n",
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's l2: 9.77465e+08\tvalid_0's l1: 18894.7\n",
      "train_mse: 600827273.53761, train_r2: 0.90425,val_mse: 977464807.91228, val_r2: 0.86594\n",
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's l2: 5.80588e+08\tvalid_0's l1: 15978.2\n",
      "train_mse: 601642385.63611, train_r2: 0.91240,val_mse: 580587827.50114, val_r2: 0.88554\n",
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's l2: 1.75494e+09\tvalid_0's l1: 21410.3\n",
      "train_mse: 589209642.07984, train_r2: 0.89822,val_mse: 1754938184.38561, val_r2: 0.77564\n",
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's l2: 1.16804e+09\tvalid_0's l1: 19232.6\n",
      "train_mse: 479486925.64499, train_r2: 0.92021,val_mse: 1168036712.36769, val_r2: 0.85561\n",
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's l2: 7.00143e+08\tvalid_0's l1: 18773.4\n",
      "train_mse: 623822566.51740, train_r2: 0.90887,val_mse: 700142528.73687, val_r2: 0.86065\n",
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's l2: 1.10306e+09\tvalid_0's l1: 18894.5\n",
      "train_mse: 715673905.82405, train_r2: 0.89183,val_mse: 1103057796.40636, val_r2: 0.77390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's l2: 6.59571e+08\tvalid_0's l1: 17725.2\n",
      "train_mse: 650023560.68658, train_r2: 0.89648,val_mse: 659571087.28820, val_r2: 0.87056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/house_price_mlops/venv/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: power_t\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's l2: 1.48507e+09\tvalid_0's l1: 21288.5\n",
      "train_mse: 439579269.16477, train_r2: 0.92795,val_mse: 1485073362.05660, val_r2: 0.80967\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08/12/22 15:32:05] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                  <a href=\"file:///var/folders/ct/3gwk63ms75j1d59250qhzlb40000gn/T/ipykernel_66368/437249340.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">437249340.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/ct/3gwk63ms75j1d59250qhzlb40000gn/T/ipykernel_66368/437249340.py#89\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">89</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Best value <span style=\"font-weight: bold\">(</span>R2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8998099615556009</span>              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[08/12/22 15:32:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                  \u001b]8;id=70282;file:///var/folders/ct/3gwk63ms75j1d59250qhzlb40000gn/T/ipykernel_66368/437249340.py\u001b\\\u001b[2m437249340.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=108543;file:///var/folders/ct/3gwk63ms75j1d59250qhzlb40000gn/T/ipykernel_66368/437249340.py#89\u001b\\\u001b[2m89\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         Best value \u001b[1m(\u001b[0mR2\u001b[1m)\u001b[0m: \u001b[1;36m0.8998099615556009\u001b[0m              \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Best hyperparameters: <span style=\"font-weight: bold\">{</span>                          <a href=\"file:///var/folders/ct/3gwk63ms75j1d59250qhzlb40000gn/T/ipykernel_66368/437249340.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">437249340.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/ct/3gwk63ms75j1d59250qhzlb40000gn/T/ipykernel_66368/437249340.py#90\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">90</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           <span style=\"color: #008000; text-decoration-color: #008000\">\"learning_rate\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.13095919455433672</span>,          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           <span style=\"color: #008000; text-decoration-color: #008000\">\"power_t\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2712582134015912</span>                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">}</span>                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Best hyperparameters: \u001b[1m{\u001b[0m                          \u001b]8;id=45736;file:///var/folders/ct/3gwk63ms75j1d59250qhzlb40000gn/T/ipykernel_66368/437249340.py\u001b\\\u001b[2m437249340.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=663146;file:///var/folders/ct/3gwk63ms75j1d59250qhzlb40000gn/T/ipykernel_66368/437249340.py#90\u001b\\\u001b[2m90\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m           \u001b[32m\"learning_rate\"\u001b[0m: \u001b[1;36m0.13095919455433672\u001b[0m,          \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           \u001b[32m\"power_t\"\u001b[0m: \u001b[1;36m0.2712582134015912\u001b[0m                  \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m}\u001b[0m                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_model()\n",
    "# optimize('./args_par.json', study_name=\"optimization\", num_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3d763c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from pathlib import Path\n",
    "import mlflow, joblib\n",
    "# CONFIG_DIR = Path(BASE_DIR, \"config\")\n",
    "\n",
    "\n",
    "\n",
    "def load_artifacts(run_id: str = None) -> Dict:\n",
    "    \"\"\"Load artifacts for a given run_id.\n",
    "    Args:\n",
    "        run_id (str): id of run to load artifacts from.\n",
    "    Returns:\n",
    "        Dict: run's artifacts.\n",
    "    \"\"\"\n",
    "    if not run_id:\n",
    "        run_id = open(Path('../config', \"run_id.txt\")).read()\n",
    "\n",
    "    # Locate specifics artifacts directory\n",
    "    experiment_id = mlflow.get_run(run_id=run_id).info.experiment_id\n",
    "    artifacts_dir = Path('../stores/model', experiment_id, run_id, \"artifacts\")\n",
    "\n",
    "    # Load objects from run\n",
    "    args = Namespace(**load_dict(filepath=Path(artifacts_dir, \"args.json\")))\n",
    "    model = joblib.load(Path(artifacts_dir, \"model.pkl\"))\n",
    "    ordinal_enc = joblib.load(Path(artifacts_dir, \"ordinal_enc.pkl\"))\n",
    "    performance = load_dict(filepath=Path(artifacts_dir, \"performance.json\"))\n",
    "\n",
    "    return {\n",
    "        \"args\": args,\n",
    "        \"model\": model,\n",
    "        \"performance\": performance,\n",
    "        \"ordinal_enc\": ordinal_enc,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea39c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts = load_artifacts()\n",
    "# !ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0b8f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(texts: List, artifacts: Dict) -> List:\n",
    "    \"\"\"Predict tags for given texts.\n",
    "    Args:\n",
    "        texts (List): raw input texts to classify.\n",
    "        artifacts (Dict): artifacts from a run.\n",
    "    Returns:\n",
    "        List: predictions for input texts.\n",
    "    \"\"\"\n",
    "    # x = texts\n",
    "    # ordinal_encode = Path(config.DATA_DIR, \"encode_cat.pkl\")\n",
    "    # enc = utilload_ordinal_encoding(ordinal_encode)\n",
    "\n",
    "    # # artifacts[\"vectorizer\"].transform(texts)\n",
    "    # predict(x)\n",
    "    print(texts)\n",
    "#     for x in texts:\n",
    "    print(artifacts[\"ordinal_enc\"].transform([[texts[3]]])[0][0])\n",
    "#         x[3] = artifacts[\"ordinal_enc\"].transform([[x[3]]])[0][0]\n",
    "#         x[3] = artifacts[\"ordinal_enc\"].transform([[x[3]]])\n",
    "    print(texts)\n",
    "    y_pred = custom_predict(\n",
    "        y_pred=artifacts[\"model\"].predict(texts),\n",
    "    )\n",
    "    # tags = artifacts[\"label_encoder\"].decode(y_pred)\n",
    "    predictions = [\n",
    "        {\n",
    "            \"input_text\": texts[i],\n",
    "            \"predicted_tag\": y_pred[i],\n",
    "        }\n",
    "        for i in range(len(y_pred))\n",
    "    ]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1d07089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11250, 7, 6, 'TA', 496, 920, 920, 866, 1786, 2]\n",
      "3.0\n",
      "[11250, 7, 6, 'TA', 496, 920, 920, 866, 1786, 2]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'custom_predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m11250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m496\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m920\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m920\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m866\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1786\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifacts\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(texts, artifacts)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#         x[3] = artifacts[\"ordinal_enc\"].transform([[x[3]]])[0][0]\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#         x[3] = artifacts[\"ordinal_enc\"].transform([[x[3]]])\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(texts)\n\u001b[0;32m---> 21\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_predict\u001b[49m(\n\u001b[1;32m     22\u001b[0m         y_pred\u001b[38;5;241m=\u001b[39martifacts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(texts),\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# tags = artifacts[\"label_encoder\"].decode(y_pred)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m         {\n\u001b[1;32m     27\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: texts[i],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_pred))\n\u001b[1;32m     31\u001b[0m     ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'custom_predict' is not defined"
     ]
    }
   ],
   "source": [
    "predict([11250,7,6,\"TA\",496,920,920,866,1786,2], artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7b07bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e675de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_splits(X: pd.Series, y: np.ndarray, train_size: float = 0.7) -> Tuple:\n",
    "    \"\"\"Generate balanced data splits.\n",
    "    Args:\n",
    "        X (pd.Series): input features.\n",
    "        y (np.ndarray): encoded labels.\n",
    "        train_size (float, optional): proportion of data to use for training. Defaults to 0.7.\n",
    "    Returns:\n",
    "        Tuple: data splits as Numpy arrays.\n",
    "    \"\"\"\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=train_size)\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db3b0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import Trial\n",
    "def objective(trial: Trial, fast_check=False, target_meter=0, return_info=False):\n",
    "    folds = 5\n",
    "    seed = 142\n",
    "    shuffle = False\n",
    "    kf = KFold(n_splits=folds, shuffle=shuffle, random_state=seed)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = get_data()\n",
    "    y_valid_pred_total = np.zeros(X_train.shape[0])\n",
    "    gc.collect()\n",
    "#     print('target_meter', target_meter, X_train.shape)\n",
    "#     L = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]\n",
    "#     categorical_features = L\n",
    "#     print('cat_features', categorical_features)\n",
    "    models = []\n",
    "    valid_score = 0\n",
    "    for train_idx, valid_idx in kf.split(X_train, y_train):\n",
    "        train_data = X_train.iloc[train_idx,:], y_train[train_idx]\n",
    "        valid_data = X_train.iloc[valid_idx,:], y_train[valid_idx]\n",
    "        print('train', len(train_idx), 'valid', len(valid_idx))\n",
    "        a, b, c = fit_lgbm(trial, train_data, valid_data, cat_features=category_cols,\n",
    "                                            num_rounds=1000)\n",
    "        model, y_pred_valid, log = a, b, c\n",
    "        y_valid_pred_total[valid_idx] = y_pred_valid\n",
    "        models.append(model)\n",
    "        gc.collect()\n",
    "        valid_score += log[\"valid/l2\"]\n",
    "        if fast_check:\n",
    "            break\n",
    "    valid_score /= len(models)\n",
    "    if return_info:\n",
    "        return valid_score, models, y_pred_valid, y_train\n",
    "    else:\n",
    "        return valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56b9f1b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Categorical parameter\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtrial\u001b[49m\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMomentumSGD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Int parameter\u001b[39;00m\n\u001b[1;32m      5\u001b[0m num_layers \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trial' is not defined"
     ]
    }
   ],
   "source": [
    "# Categorical parameter\n",
    "optimizer = trial.suggest_categorical('optimizer', ['MomentumSGD', 'Adam'])\n",
    "\n",
    "# Int parameter\n",
    "num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "\n",
    "# Uniform parameter\n",
    "dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 1.0)\n",
    "\n",
    "# Loguniform parameter\n",
    "learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "\n",
    "# Discrete-uniform parameter\n",
    "drop_path_rate = trial.suggest_discrete_uniform('drop_path_rate', 0.0, 1.0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fe5fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgbm(trial, train, val, devices=(-1,), seed=None, cat_features=None, num_rounds=1500):\n",
    "    \"\"\"Train Light GBM model\"\"\"\n",
    "    X_train, y_train = train\n",
    "    X_valid, y_valid = val\n",
    "    metric = 'l2'\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'objective': 'regression',\n",
    "        'max_depth': -1,\n",
    "        'learning_rate': 0.1,\n",
    "        \"boosting\": \"gbdt\",\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        \"bagging_freq\": 5,\n",
    "        \"bagging_fraction\": trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
    "        \"feature_fraction\": trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        \"metric\": metric,\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "    device = devices[0]\n",
    "    if device == -1:\n",
    "        # use cpu\n",
    "        pass\n",
    "    else:\n",
    "        # use gpu\n",
    "        print(f'using gpu device_id {device}...')\n",
    "        params.update({'device': 'gpu', 'gpu_device_id': device})\n",
    "\n",
    "    params['seed'] = seed\n",
    "\n",
    "    early_stop = 20\n",
    "    verbose_eval = 20\n",
    "\n",
    "    d_train = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_features)\n",
    "    d_valid = lgb.Dataset(X_valid, label=y_valid, categorical_feature=cat_features)\n",
    "    watchlist = [d_train, d_valid]\n",
    "\n",
    "    print('training LGB:')\n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=num_rounds,\n",
    "                      valid_sets=watchlist,\n",
    "                      verbose_eval=verbose_eval,\n",
    "                      early_stopping_rounds=early_stop)\n",
    "\n",
    "    # predictions\n",
    "    y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    \n",
    "    print('best_score', model.best_score)\n",
    "    log = {'train/l2': model.best_score['training']['l2'],\n",
    "           'valid/l2': model.best_score['valid_1']['l2']}\n",
    "    return model, y_pred_valid, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1deffe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb952d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea0326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643f01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0aa968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb70dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be172fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac13e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a527c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,  X_test, y_train,  y_test = train_test_split(\n",
    "        df[df.columns[~df.columns.isin([\"SalePrice\"])]].to_numpy(),\n",
    "        df.SalePrice.to_numpy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_, y_train, y_ = train_test_split(X, y, train_size=train_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "912911cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,  X_test, y_train,  y_test = train_test_split(\n",
    "        X_test,y_test\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c58232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get ordinal encode dict\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd0723f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gd', 'TA', 'Ex', nan, 'Fa'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BsmtQual'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37cf3cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "df['tr']=enc.fit_transform(df[['BsmtQual']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25fb3975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>tr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>Gd</td>\n",
       "      <td>706</td>\n",
       "      <td>856</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>1710</td>\n",
       "      <td>2</td>\n",
       "      <td>208500</td>\n",
       "      <td>2008</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>Gd</td>\n",
       "      <td>978</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>181500</td>\n",
       "      <td>2007</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>Gd</td>\n",
       "      <td>486</td>\n",
       "      <td>920</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>1786</td>\n",
       "      <td>2</td>\n",
       "      <td>223500</td>\n",
       "      <td>2008</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>TA</td>\n",
       "      <td>216</td>\n",
       "      <td>756</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>1717</td>\n",
       "      <td>3</td>\n",
       "      <td>140000</td>\n",
       "      <td>2006</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Gd</td>\n",
       "      <td>655</td>\n",
       "      <td>1145</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>2198</td>\n",
       "      <td>3</td>\n",
       "      <td>250000</td>\n",
       "      <td>2008</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea  OverallQual  YearRemodAdd BsmtQual  BsmtFinSF1  TotalBsmtSF  \\\n",
       "0     8450            7             5       Gd         706          856   \n",
       "1     9600            6            31       Gd         978         1262   \n",
       "2    11250            7             6       Gd         486          920   \n",
       "3     9550            7            36       TA         216          756   \n",
       "4    14260            8             8       Gd         655         1145   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  GrLivArea  GarageCars  SalePrice  YrSold   tr  \n",
       "0       856       854       1710           2     208500    2008  2.0  \n",
       "1      1262         0       1262           2     181500    2007  2.0  \n",
       "2       920       866       1786           2     223500    2008  2.0  \n",
       "3       961       756       1717           3     140000    2006  3.0  \n",
       "4      1145      1053       2198           3     250000    2008  2.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "397c7dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_check_X',\n",
       " '_check_n_features',\n",
       " '_fit',\n",
       " '_get_feature',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_transform',\n",
       " '_validate_data',\n",
       " 'categories',\n",
       " 'categories_',\n",
       " 'dtype',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'get_params',\n",
       " 'handle_unknown',\n",
       " 'inverse_transform',\n",
       " 'set_params',\n",
       " 'transform',\n",
       " 'unknown_value']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d25691c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'non_deterministic': False,\n",
       " 'requires_positive_X': False,\n",
       " 'requires_positive_y': False,\n",
       " 'X_types': ['categorical'],\n",
       " 'poor_score': False,\n",
       " 'no_validation': False,\n",
       " 'multioutput': False,\n",
       " 'allow_nan': False,\n",
       " 'stateless': False,\n",
       " 'multilabel': False,\n",
       " '_skip_test': False,\n",
       " '_xfail_checks': False,\n",
       " 'multioutput_only': False,\n",
       " 'binary_only': False,\n",
       " 'requires_fit': True,\n",
       " 'preserves_dtype': [numpy.float64],\n",
       " 'requires_y': False,\n",
       " 'pairwise': False}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc._get_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cd5a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
